{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 17\n",
    "SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gx_utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from random import seed, choice\n",
    "from typing import Callable\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this situation the state is the board that contains all possible actions\n",
    "class State:\n",
    "    def __init__(self, data: np.ndarray):\n",
    "        self._data = data.copy()\n",
    "        self._data.flags.writeable = False\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(bytes(self._data))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return bytes(self._data) == bytes(other._data)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return bytes(self._data) < bytes(other._data)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self._data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self._data)\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "\n",
    "    def copy_data(self):\n",
    "        return self._data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    initial_state: State,\n",
    "    goal_test: Callable,\n",
    "    parent_state: dict,\n",
    "    state_cost: dict,\n",
    "    priority_function: Callable,\n",
    "    unit_cost: Callable,\n",
    "):\n",
    "    frontier = PriorityQueue()\n",
    "    parent_state.clear()\n",
    "    state_cost.clear()\n",
    "\n",
    "    state = initial_state\n",
    "    parent_state[state] = None\n",
    "    state_cost[state] = 0\n",
    "\n",
    "    while state is not None and not goal_test(state):\n",
    "        for a in possible_actions(state): \n",
    "            new_state = result(state, a) # this is what happens to the previous state if i apply the action a\n",
    "            cost = unit_cost(a) # compute the cost\n",
    "            if new_state not in state_cost and new_state not in frontier:\n",
    "                parent_state[new_state] = state\n",
    "                state_cost[new_state] = state_cost[state] + cost # append to the dict of costs the cost corresponding to the new_state\n",
    "                frontier.push(new_state, p=priority_function(new_state)) # append with a specified priority function\n",
    "                logging.debug(f\"Added new node to frontier (cost={state_cost[new_state]})\")\n",
    "            elif new_state in frontier and state_cost[new_state] > state_cost[state] + cost:\n",
    "                old_cost = state_cost[new_state]\n",
    "                parent_state[new_state] = state\n",
    "                state_cost[new_state] = state_cost[state] + cost\n",
    "                logging.debug(f\"Updated node cost in frontier: {old_cost} -> {state_cost[new_state]}\")\n",
    "        if frontier:\n",
    "            state = frontier.pop()\n",
    "        else:\n",
    "            state = None\n",
    "\n",
    "    path = list()\n",
    "    s = state\n",
    "    while s:\n",
    "        path.append(s.copy_data())\n",
    "        s = parent_state[s]\n",
    "\n",
    "    logging.info(f\"Found a solution in {len(path):,} steps; visited {len(state_cost):,} states\")\n",
    "    return list(reversed(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph search for the the n-puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not a time-dependent problem, so given the goal it will remain the same overtime\n",
    "GOAL = State(np.array(list(range(1, SIZE**2)) + [0]).reshape((SIZE, SIZE)))\n",
    "logging.info(f\"Goal:\\n{GOAL}\")\n",
    "\n",
    "\n",
    "def goal_test(state):\n",
    "    return state == GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (R, C) -> UP / RIGHT / DOWN / LEFT, all the possible moves are encoded in an array\n",
    "# an action is a possible move and if you are in the middle you can do 4 possible moves,\n",
    "# instead if you are in the corner you can do just 2 moves\n",
    "# and if you are on the side you can do 3 possible moves\n",
    "MOVES = [np.array(_) for _ in [(-1, 0), (0, +1), (+1, 0), (0, -1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empty_space(board: np.ndarray):\n",
    "    t = np.where(board == 0)\n",
    "    return np.array([t[0][0], t[1][0]])\n",
    "\n",
    "\n",
    "def is_valid(board: np.ndarray, action):\n",
    "    return all(0 <= (find_empty_space(board) + action)[i] < board.shape[i] for i in [0, 1])\n",
    "\n",
    "\n",
    "def possible_actions(state: State):\n",
    "    return (m for m in MOVES if is_valid(state._data, m))\n",
    "    # this function returns a generator (like range) so an object on which i can apply the function next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(state, action):\n",
    "    board = state.copy_data()\n",
    "    space = find_empty_space(board)\n",
    "    pos = space + action\n",
    "    board[space[0], space[1]] = board[pos[0], pos[1]]\n",
    "    board[pos[0], pos[1]] = 0\n",
    "    return State(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_STATE = GOAL\n",
    "for r in range(500):\n",
    "    INITIAL_STATE = result(INITIAL_STATE, choice(list(possible_actions(INITIAL_STATE))))\n",
    "INITIAL_STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth-First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_state = dict()\n",
    "state_cost = dict()\n",
    "\n",
    "final = search(\n",
    "    INITIAL_STATE,\n",
    "    goal_test=goal_test,\n",
    "    parent_state=parent_state,\n",
    "    state_cost=state_cost,\n",
    "    priority_function=lambda s: len(state_cost), # the priority is the breadth so the len of possible actions, \n",
    "                                                #i'm handling the states in the very same order i discover them \n",
    "    unit_cost=lambda a: 1, # the cost of the action is 1 so i just want to find the shortest path\n",
    ")\n",
    "# it finds the solution in 25 steps and this is the minimum because it is the shortest path to reach the goal\n",
    "# first: all possible solutions one step away, then all possible solutions two steps away and so on.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the cost was not 1 we could have used a Dijkstra's search which is going  to expand the closest nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth-First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_state = dict()\n",
    "state_cost = dict()\n",
    "\n",
    "final = search(\n",
    "    INITIAL_STATE,\n",
    "    goal_test=goal_test,\n",
    "    parent_state=parent_state,\n",
    "    state_cost=state_cost,\n",
    "    priority_function=lambda s: -len(state_cost), # here the priority function is LIFO basically\n",
    "    unit_cost=lambda a: 1,\n",
    ")\n",
    "# his solution contains 65813 steps even though the number of visited states is less then the first one. \n",
    "# so the solution is dumb but it is faster\n",
    "# we can also set a threshold to the state_cost and it will take less steps but if we choose the threshold unwisly we risk to not find the right solution or any solution\n",
    "# we cannot set a threshold to the breadth first, it is usually used on this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gready Best-First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_state = dict()\n",
    "state_cost = dict()\n",
    "\n",
    "# if any state is in some way similar (close) to the final one, then use that as solution.  \n",
    "def h(state):\n",
    "    return np.sum((state._data != GOAL._data) & (state._data > 0))\n",
    "\n",
    "\n",
    "final = search(\n",
    "    INITIAL_STATE,\n",
    "    goal_test=goal_test,\n",
    "    parent_state=parent_state,\n",
    "    state_cost=state_cost,\n",
    "    priority_function=lambda s: h(s), \n",
    "    unit_cost=lambda a: 1,\n",
    ")\n",
    "# this is not always correct. we can notice that it reaches 49 steps (less than breadth first, but more than depth first) but it takes less states than the other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_state = dict()\n",
    "state_cost = dict()\n",
    "\n",
    "def h(state):\n",
    "    return np.sum((state._data != GOAL._data) & (state._data > 0))\n",
    "\n",
    "\n",
    "final = search(\n",
    "    INITIAL_STATE,\n",
    "    goal_test=goal_test,\n",
    "    parent_state=parent_state,\n",
    "    state_cost=state_cost,\n",
    "    priority_function=lambda s: state_cost[s] + h(s),\n",
    "    unit_cost=lambda a: 1,#      | safe part     | greedy part\n",
    ")\n",
    "# In this way i'm able to find the solution which contains 25 steps but with a reasonable number of steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
